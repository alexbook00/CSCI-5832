{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wireless-letter",
   "metadata": {},
   "source": [
    "# CSCI 5832 - Natural Language Processing\n",
    "# Assignment 2: Logistic Regression and Sentiment Analysis\n",
    "#### Author: Alex Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "three-aside",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ordered-medicine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill array of positive words\n",
    "pos_words = []\n",
    "with open('positive-words.txt') as f:\n",
    "    for line in f:\n",
    "        pos_words.append(line.split()[0])\n",
    "        \n",
    "# fill array of negative words\n",
    "neg_words = []\n",
    "with open('negative-words.txt') as f:\n",
    "    for line in f:\n",
    "        neg_words.append(line.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pressed-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows stripping of punctuation from strings\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "# define pronouns array\n",
    "pronouns = ['i', 'me', 'mine', 'my', 'you', 'your', 'yours', 'we', 'us', 'ours']\n",
    "\n",
    "def get_features_from_reviews(file):\n",
    "    with open(file, encoding=\"utf8\") as f:\n",
    "        # initialize array of features vectors\n",
    "        features_vectors = []\n",
    "        \n",
    "        for line in f:\n",
    "            # initialize features vector\n",
    "            features = ['ID', 0, 0, 0, 0, 0, 0, 'Class']\n",
    "            \n",
    "            # getting \n",
    "            if 'Pos' in file:\n",
    "                features[-1] = 1\n",
    "            else:\n",
    "                features[-1] = 0\n",
    "\n",
    "            # check for feature 3\n",
    "            if 'no' in line.lower():\n",
    "                features[3] = 1\n",
    "\n",
    "            # check for feature 5\n",
    "            if '!' in line:\n",
    "                features[5] = 1\n",
    "\n",
    "            # split review by spaces\n",
    "            arr = line.split()\n",
    "            \n",
    "            # get ID\n",
    "            features[0] = arr[0]\n",
    "\n",
    "            # get feature 6 (length minus one due to the ID being the first 'word')\n",
    "            features[6] = np.log(len(arr)-1)\n",
    "\n",
    "            # get remaining features\n",
    "            for word in arr[1:]:\n",
    "                # put word to lowercase and remove any punctuation\n",
    "                word = word.lower().translate(translator)\n",
    "                \n",
    "                # check for contribution to feature 1\n",
    "                if word in pos_words:\n",
    "                    features[1] += 1\n",
    "                    \n",
    "                # check for contribution to feature 2\n",
    "                if word in neg_words:\n",
    "                    features[2] += 1\n",
    "                    \n",
    "                # check for contribution to feature 4\n",
    "                if word in pronouns:\n",
    "                    features[4] += 1\n",
    "            \n",
    "            # append features vector to array holding all of them\n",
    "            features_vectors.append(features)\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "        return features_vectors\n",
    "\n",
    "all_features_vectors = get_features_from_reviews('hotelPosT-train.txt') + get_features_from_reviews('hotelNegT-train.txt')\n",
    "\n",
    "# output to csv\n",
    "with open('Book-Alex-assgn2-part1.csv', 'w', newline='') as outfile:\n",
    "    csvWriter = csv.writer(outfile, delimiter=',')\n",
    "    csvWriter.writerows(all_features_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(L, f, x, y):\n",
    "    # L is the loss function (in this case we use Cross Entropy)\n",
    "    # f is our estimated output function (use the sigmoid function: 1/(1 + e^-(w dot x + b)) where w is the weights, x is the features, and b is the bias term)\n",
    "    # x is the set of training inputs (feature vectors)\n",
    "    # y is the set of training output (labels)\n",
    "    \n",
    "    # for each training tuple (x, y) (in random order):\n",
    "        # optional (for reporting): how are we doing on this tuple?\n",
    "        # compute our estimated output\n",
    "        # compute the loss\n",
    "        # how should we move the set of weights to maximize loss?\n",
    "        # go the other way instead\n",
    "    # return set of weights\n",
    "    \n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
